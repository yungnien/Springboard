{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>USING SPARK </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains the flow for traditional machine learning steps  scale to spark:\n",
    "\n",
    " 1. data import\n",
    " 2. data wrangling for NLP\n",
    " 3. train-test-hold data split\n",
    " 4. Imbalanced data treatment \n",
    " 5. BOW (bag of words) machine learning \n",
    "     NaviebBayes \n",
    "     hyper-parameter turning  on GBX and LogisticRegression\n",
    " 6. Simple Network \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.session.SparkSession'> <class 'pyspark.context.SparkContext'> <class 'pyspark.sql.context.SQLContext'>\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "print(type(spark),type(sc),type(sqlCtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "sc\n",
    "sqlCtx\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set: 1306122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "print('Training data set: ' + str(len(train_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      "qid              1306122 non-null object\n",
      "question_text    1306122 non-null object\n",
      "target           1306122 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# from pyspark.sql.types import StructType, StructField\n",
    "# from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "# schema = StructType([\n",
    "#     StructField(\"qid\", StringType()),\n",
    "#     StructField(\"question_text\", StringType()),\n",
    "#     StructField(\"target\", IntegerType())\n",
    "# ])\n",
    "\n",
    "# spark_train_1 = spark.read.csv('data/train.csv', header = True, inferSchema = True)\n",
    "# spark_train_2 =  spark.read.load(\"data/train.csv\", parserLib= \"univocity\", charset=\"ISO-8859-1\", format = \"csv\", sep = \",\", schema = schema, header=\"true\")\n",
    "\n",
    "# print('Training data set: ' + str(spark_train_data1.count()))\n",
    "# print('Training data set: ' + str(spark_train_data2.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>The above is not working, as for now, the spark file loading has problem on double quote, the work around is to load from pandas dataframe [CSV I/O: does not respect RFC 4180](https://issues.apache.org/jira/browse/SPARK-22236)</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark_train_data = sqlCtx.createDataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- question_text: string (nullable = true)\n",
      " |-- target: long (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|summary|                 qid|       question_text|             target|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|  count|             1306122|             1306122|            1306122|\n",
      "|   mean|            Infinity|                null|0.06187017751787352|\n",
      "| stddev|                 NaN|                null| 0.2409197025783378|\n",
      "|    min|00002165364db923c7e6|\u0010I want to blow t...|                  0|\n",
      "|    max|ffffed09fedb5088744a|￼￼Assuming that a...|                  1|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "\n",
      "Training data set: 1306122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(qid='00002165364db923c7e6', question_text='How did Quebec nationalists see their province as a nation in the 1960s?', target=0),\n",
       " Row(qid='000032939017120e6e44', question_text='Do you have an adopted dog, how would you encourage people to adopt and not shop?', target=0),\n",
       " Row(qid='0000412ca6e4628ce2cf', question_text='Why does velocity affect time? Does velocity affect space geometry?', target=0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_train_data.printSchema()\n",
    "spark_train_data.describe().show()\n",
    "print('Training data set: ' + str(spark_train_data.count()))\n",
    "spark_train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preserve the data for later\n",
    "spark_train_data.write.mode('overwrite').parquet(\"data/spark_train_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2.1 DATA WRANGLING, simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- qid: string (nullable = true)\n",
      " |-- question_text: string (nullable = true)\n",
      " |-- target: long (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|summary|                 qid|       question_text|             target|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|  count|             1306122|             1306122|            1306122|\n",
      "|   mean|            Infinity|                null|0.06187017751787352|\n",
      "| stddev|                 NaN|                null| 0.2409197025783378|\n",
      "|    min|00002165364db923c7e6|\u0010I want to blow t...|                  0|\n",
      "|    max|ffffed09fedb5088744a|￼￼Assuming that a...|                  1|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "\n",
      "Training data set: 1306122\n",
      "CPU times: user 11.8 ms, sys: 1.12 ms, total: 12.9 ms\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark_train_data = spark.read.parquet(\"data/spark_train_data.parquet\")\n",
    "spark_train_data.printSchema()\n",
    "spark_train_data.describe().show()\n",
    "print('Training data set: ' + str(spark_train_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /usr/local/anaconda/lib/python3.6/site-packages (0.0.18)\n",
      "\u001b[31mpyspark 2.4.0 requires py4j==0.10.7, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import lower, col\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "def remove_white_space(text):\n",
    "    return text.strip().strip('\\t\\n')\n",
    "def remove_special_character(text):\n",
    "    return re.sub('[^A-Za-z0-9\\s]+', '', text)\n",
    "# F1 perform contractions fix and three functions as above, to lower case will use the sql functon from pyspark\n",
    "dataClean = udf(lambda x: remove_special_character(contractions.fix(remove_white_space(remove_non_ascii(x)))), StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.93 ms, sys: 7.26 ms, total: 12.2 ms\n",
      "Wall time: 88.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark_train_data = spark_train_data.withColumn('origin', col('question_text'))\n",
    "spark_train_data = spark_train_data.withColumn('label', col('target').cast('int'))\n",
    "spark_train_data = spark_train_data.withColumn(\"question_text\",lower(dataClean(spark_train_data[\"question_text\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#spark_train_data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 spark tokenization, stop word removing and Naivebayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "#tokenizer = Tokenizer(inputCol=\"question_text\", outputCol=\"words\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"question_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "# reduce calculation time and sparse, set vocab size to 65536\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=65536) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 113 ms, sys: 28.6 ms, total: 141 ms\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors])\n",
    "pipelineFit = pipeline.fit(spark_train_data)\n",
    "spark_train_data = pipelineFit.transform(spark_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.22 ms, sys: 0 ns, total: 8.22 ms\n",
      "Wall time: 59.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "spark_train_data = spark_train_data.withColumn(\"tokens\", countTokens(col(\"filtered\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                 qid|       question_text|target|              origin|label|               words|            filtered|            features|\n",
      "+--------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|40073653a1341fd91860|name some small t...|     0|Name some small t...|    0|[name, some, smal...|[name, small, tow...|(65536,[3,64,93,2...|\n",
      "|4007527f139de5f2091e|a 15minute boat r...|     0|A 15-minute boat ...|    0|[a, 15minute, boa...|[15minute, boat, ...|(65536,[284,450,4...|\n",
      "+--------------------+--------------------+------+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 1.92 ms, sys: 619 µs, total: 2.54 ms\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark_train_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 ms, sys: 6.79 ms, total: 27.8 ms\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#preserve the data for later\n",
    "spark_train_data = spark_train_data.select(\"features\",\"label\")\n",
    "spark_train_data.write.mode('overwrite').parquet(\"data/spark_train_data_count.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "# reduce calculation time and sparse, restrict the features\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=65536)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 16.5 ms, total: 134 ms\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf])\n",
    "pipelineFit = pipeline.fit(spark_train_data)\n",
    "spark_train_data = pipelineFit.transform(spark_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#spark_train_data.show(2,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 ms, sys: 5.15 ms, total: 27.4 ms\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#preserve the data for later\n",
    "spark_train_data = spark_train_data.select(\"features\",\"label\")\n",
    "spark_train_data.write.mode('overwrite').parquet(\"data/spark_train_data_tfidf.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#spark_train_data.show(2,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 TRAIN-TEST-HOLD DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|            1306122|\n",
      "|   mean|0.06187017751787352|\n",
      "| stddev|0.24091970257833784|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "Training data set: 1306122\n",
      "+--------------------------------------------------------+-----+\n",
      "|features                                                |label|\n",
      "+--------------------------------------------------------+-----+\n",
      "|(65536,[22,1309,35260],[1.0,1.0,1.0])                   |0    |\n",
      "|(65536,[441,1046,1570,4267,28286],[1.0,1.0,1.0,1.0,1.0])|0    |\n",
      "+--------------------------------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 13 ms, sys: 199 µs, total: 13.2 ms\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark_train_data = spark.read.parquet(\"data/spark_train_data_count.parquet\")\n",
    "spark_train_data.printSchema()\n",
    "spark_train_data.describe().show()\n",
    "print('Training data set: ' + str(spark_train_data.count()))\n",
    "spark_train_data.show(2,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 ms, sys: 0 ns, total: 2.57 ms\n",
      "Wall time: 862 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "insincere = spark_train_data.filter(spark_train_data['label'] > 0)\n",
    "sincere = spark_train_data.filter(spark_train_data['label'] <= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80810 1225312\n"
     ]
    }
   ],
   "source": [
    "print(insincere.count(), sincere.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260061 208417 209080 837644\n",
      "CPU times: user 20.6 ms, sys: 309 µs, total: 20.9 ms\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(train_1, hold_1) = insincere.randomSplit([0.8, 0.2], seed = 42)\n",
    "(train_0, hold_0) = sincere.randomSplit([0.8, 0.2], seed = 42)\n",
    "hold = hold_1.unionAll(hold_0)\n",
    "\n",
    "(train_1, test_1) = train_1.randomSplit([0.8, 0.2], seed = 42)\n",
    "(train_0, test_0) = train_0.randomSplit([0.8, 0.2], seed = 42)\n",
    "test = test_1.unionAll(test_0)\n",
    "\n",
    "(train_1_25, train_1_75) = train_1.randomSplit([0.25, 0.75], seed = 42)\n",
    "(train_0_25, train_0_75) = train_0.randomSplit([0.25, 0.75], seed = 42)\n",
    "train_25 = train_1_25.unionAll(train_0_25)\n",
    "train = train_1.unionAll(train_0)\n",
    "\n",
    "print(hold.count(), test.count(), train_25.count(), train.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 IMBALANCED DATA TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>simple down sampling</B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149182\n",
      "CPU times: user 6.18 ms, sys: 0 ns, total: 6.18 ms\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "size =  2 * (train_1.count() / (train_1.count() + train_0.count()))\n",
    "(train_0_d, _) = train_0.randomSplit([size, 1-size], seed = 42)\n",
    "train_balanced = train_1.unionAll(train_0_d)\n",
    "print(train_balanced.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10370\n"
     ]
    }
   ],
   "source": [
    "(train_1_10, _) = train_1.randomSplit([0.10, 0.90], seed = 42)\n",
    "size =   train_1_10.count() / train_0.count()\n",
    "(train_0_10, _) = train_0.randomSplit([size, 1-size], seed = 42)\n",
    "train_small = train_1_10.unionAll(train_0_10)\n",
    "print(train_small.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=5170), Row(label=0, count=5200)]\n",
      "CPU times: user 14.1 ms, sys: 4.81 ms, total: 18.9 ms\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(train_small.groupBy('label').count().collect())\n",
    "train_small.write.mode('overwrite').parquet(\"data/train_small.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=16056), Row(label=0, count=244005)]\n",
      "CPU times: user 10.1 ms, sys: 1 ms, total: 11.1 ms\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(hold.groupBy('label').count().collect())\n",
    "hold.write.mode('overwrite').parquet(\"data/hold.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=51833), Row(label=0, count=97349)]\n",
      "CPU times: user 8.71 ms, sys: 1.9 ms, total: 10.6 ms\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(train_balanced.groupBy('label').count().collect())\n",
    "train_balanced.write.mode('overwrite').parquet(\"data/train_balanced.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=12799), Row(label=0, count=196281)]\n",
      "CPU times: user 4.32 ms, sys: 5.82 ms, total: 10.1 ms\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(train_25.groupBy('label').count().collect())\n",
    "train_25.write.mode('overwrite').parquet(\"data/train_25.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=12921), Row(label=0, count=195496)]\n",
      "CPU times: user 7.41 ms, sys: 5.4 ms, total: 12.8 ms\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(test.groupBy('label').count().collect())\n",
    "test.write.mode('overwrite').parquet(\"data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=51833), Row(label=0, count=785811)]\n",
      "CPU times: user 15 ms, sys: 1.77 ms, total: 16.8 ms\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(train.groupBy('label').count().collect())\n",
    "train.write.mode('overwrite').parquet(\"data/train.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5.1 BAG OF WORDS  MACHINE LEARNING  NaviebBayes, LogisticRegression and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.12 ms, sys: 548 µs, total: 8.67 ms\n",
      "Wall time: 9.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hold = spark.read.parquet(\"data/hold.parquet\")\n",
    "test = spark.read.parquet(\"data/test.parquet\")\n",
    "train_balanced = spark.read.parquet(\"data/train_balanced.parquet\")\n",
    "train_25 = spark.read.parquet(\"data/train_25.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_small = spark.read.parquet(\"data/train_small.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>clean up dataset as there are zero features from feature transform pipeline</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def is_null(text):\n",
    "    return text[1] < 1\n",
    "\n",
    "featureClean = udf(lambda x: not is_null(x), BooleanType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 229 ms, sys: 27.2 ms, total: 256 ms\n",
      "Wall time: 599 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hold = hold.filter(featureClean(hold.features))\n",
    "test = test.filter(featureClean(test.features))\n",
    "train_25 = train_25.filter(featureClean(train_25.features))\n",
    "train_balanced = train_balanced.filter(featureClean(train_balanced.features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_small = train_small.filter(featureClean(train_small.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=122), Row(label=0, count=12236)]\n",
      "[Row(label=1, count=113), Row(label=0, count=9785)]\n",
      "[Row(label=1, count=109), Row(label=0, count=9718)]\n",
      "[Row(label=1, count=411), Row(label=0, count=4853)]\n",
      "CPU times: user 79.9 ms, sys: 20.7 ms, total: 101 ms\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(hold.groupBy('label').count().collect())\n",
    "print(test.groupBy('label').count().collect())\n",
    "print(train_25.groupBy('label').count().collect())\n",
    "print(train_balanced.groupBy('label').count().collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=48), Row(label=0, count=263)]\n"
     ]
    }
   ],
   "source": [
    "print(train_small.groupBy('label').count().collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>NaiveBayes</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33436096127408216, 0.33436096127408216, 0.3343609612740822, 0.3343609612740821, 0.3343609612740822, 0.33436096127408216, 0.3343609612740822, 0.33436096127408216]\n",
      "CPU times: user 1.66 s, sys: 314 ms, total: 1.98 s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramMaps = ParamGridBuilder()\\\n",
    "    .addGrid(NaiveBayes.modelType, ['multinomial', 'bernoulli'])\\\n",
    "    .addGrid(NaiveBayes.smoothing, [0.1, 0.5, 1.0, 1.5])\\\n",
    "    .build()\n",
    "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "\n",
    "crossval = CrossValidator(estimator=NaiveBayes(),estimatorParamMaps= paramMaps, evaluator= evaluator, numFolds=5)\n",
    "cvModel = crossval.fit(train_balanced)\n",
    "print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectSubModels: Param for whether to collect a list of sub-models trained during tuning. If set to false, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. (default: False)\n",
      "estimator: estimator to be cross-validated (current: NaiveBayes_eed55a48a064)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'multinomial', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.1}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'multinomial', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.5}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'multinomial', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.0}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'multinomial', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.5}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'bernoulli', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.1}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'bernoulli', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 0.5}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'bernoulli', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.0}, {Param(parent='undefined', name='modelType', doc='The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.'): 'bernoulli', Param(parent='undefined', name='smoothing', doc='The smoothing parameter, should be >= 0, default is 1.0'): 1.5}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_4f4ada434e98)\n",
      "numFolds: number of folds for cross validation (default: 3, current: 5)\n",
      "parallelism: the number of threads to use when running parallel algorithms (>= 1). (default: 1)\n",
      "seed: random seed. (default: 7809051150349531440)\n"
     ]
    }
   ],
   "source": [
    "print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3551042999965405\n",
      "0.3685485730823327\n",
      "  \n",
      "9898\n",
      "9787\n",
      "111\n",
      "CPU times: user 165 ms, sys: 18 ms, total: 183 ms\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bestNaive = cvModel.bestModel\n",
    "train_pred = bestNaive.transform(train_balanced)\n",
    "train_auc = evaluator.evaluate(train_pred)\n",
    "print(train_auc)\n",
    "test_pred = bestNaive.transform(test)\n",
    "test_auc = evaluator.evaluate(test_pred)\n",
    "print(test_auc)\n",
    "print(\"  \")\n",
    "print(test_pred.count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>LogisticRegression</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8177076381522643, 0.8177076381522642, 0.8177076381522643, 0.8177076381522641, 0.8177076381522641, 0.8177076381522642, 0.8177076381522642, 0.8177076381522641, 0.8177076381522641, 0.8177076381522641, 0.8177076381522644, 0.817707638152264, 0.8177076381522643, 0.8177076381522641, 0.8177076381522643, 0.8177076381522641, 0.8177076381522644, 0.8177076381522643, 0.8177076381522645, 0.8177076381522641, 0.8177076381522641, 0.8177076381522641, 0.817707638152264, 0.8177076381522641, 0.817707638152264, 0.8177076381522641, 0.817707638152264, 0.8177076381522641, 0.8177076381522645, 0.8177076381522642, 0.8177076381522642, 0.8177076381522641, 0.8177076381522643, 0.8177076381522641, 0.8177076381522643, 0.8177076381522642, 0.8177076381522643, 0.8177076381522641, 0.8177076381522643, 0.8177076381522641, 0.8177076381522641, 0.8177076381522641, 0.8177076381522642, 0.8177076381522641, 0.8177076381522639, 0.8177076381522642, 0.8177076381522645, 0.8177076381522641]\n",
      "CPU times: user 16.7 s, sys: 3.83 s, total: 20.6 s\n",
      "Wall time: 16min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "paramMaps = ParamGridBuilder()\\\n",
    "            .addGrid(LogisticRegression.maxIter, [10, 50, 100])\\\n",
    "            .addGrid(LogisticRegression.regParam, [0.01, 0.1, 1.0, 10])\\\n",
    "            .addGrid(LogisticRegression.elasticNetParam, [0, 0.3, 0.6, 1])\\\n",
    "            .build()\n",
    "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "#evaluator = RegressionEvaluator(metricName = \"r2\")  f1|weightedPrecision|weightedRecall|accuracy)\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName = \"f1\")\n",
    "\n",
    "\n",
    "crossval = CrossValidator(estimator = estimator,estimatorParamMaps = paramMaps, evaluator = evaluator, numFolds = 5)\n",
    "cvModel = crossval.fit(train_balanced)\n",
    "print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectSubModels: Param for whether to collect a list of sub-models trained during tuning. If set to false, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. (default: False)\n",
      "estimator: estimator to be cross-validated (current: LogisticRegression_d1aa6f6acd9e)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.6}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_35c1f1aa569e)\n",
      "numFolds: number of folds for cross validation (default: 3, current: 5)\n",
      "parallelism: the number of threads to use when running parallel algorithms (>= 1). (default: 1)\n",
      "seed: random seed. (default: 7809051150349531440)\n"
     ]
    }
   ],
   "source": [
    "print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.8124092773388885\n",
      "  \n",
      "9898\n",
      "9447\n",
      "451\n",
      "CPU times: user 178 ms, sys: 31.5 ms, total: 209 ms\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bestLogistic = cvModel.bestModel\n",
    "train_pred = bestLogistic.transform(train_balanced)\n",
    "train_auc = evaluator.evaluate(train_pred)\n",
    "print(train_auc)\n",
    "test_pred = bestLogistic.transform(test)\n",
    "test_auc = evaluator.evaluate(test_pred)\n",
    "print(test_auc)\n",
    "print(\"  \")\n",
    "print(test_pred.count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())\n",
    "\n",
    "# calculate results \n",
    "# r = train_pred.stat.corr(\"prediction\", \"label\")\n",
    "# print(\"R-sqaured: \" + str(r**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.27404868371536206\n",
      "0.1273490866044008\n",
      "0.08254727768078535\n",
      "0.06468886600160602\n",
      "0.04152607490129559\n",
      "0.034992609702753315\n",
      "0.030756827356619738\n",
      "0.018648170286254928\n",
      "0.010391922762000032\n",
      "0.0067322612803490545\n",
      "0.004209617677492705\n",
      "0.0027907206806629913\n",
      "0.0018466033438254569\n",
      "0.0009730560886763704\n",
      "0.0006127332257943605\n",
      "0.00039503086426880793\n",
      "0.00026347696929724464\n",
      "0.0001622487233018019\n",
      "3.579882784406424e-05\n",
      "2.5525197994162546e-05\n",
      "1.0995128455427055e-05\n",
      "5.820016707578058e-06\n",
      "2.890317775447016e-06\n",
      "1.6821906947139898e-06\n",
      "9.391355946984973e-07\n",
      "4.708336356085494e-07\n",
      "2.8172511220718963e-07\n",
      "9.791689423050575e-08\n",
      "6.46949119449137e-08\n",
      "2.952431128776676e-08\n",
      "1.4439837320307307e-08\n",
      "4.608749084991078e-09\n",
      "3.099071923794927e-09\n",
      "+--------------------+------------------+\n",
      "|                 FPR|               TPR|\n",
      "+--------------------+------------------+\n",
      "|                 0.0|               0.0|\n",
      "|                 0.0|0.8077858880778589|\n",
      "|                 0.0|0.9245742092457421|\n",
      "|0.003502987842571...|               1.0|\n",
      "| 0.01359983515351329|               1.0|\n",
      "|0.023490624356068412|               1.0|\n",
      "|0.033381413558623535|               1.0|\n",
      "|0.043478260869565216|               1.0|\n",
      "| 0.05336905007212034|               1.0|\n",
      "| 0.06325983927467546|               1.0|\n",
      "| 0.07315062847723058|               1.0|\n",
      "|  0.0830414176797857|               1.0|\n",
      "| 0.09293220688234081|               1.0|\n",
      "| 0.10282299608489594|               1.0|\n",
      "| 0.11291984339583763|               1.0|\n",
      "| 0.12281063259839274|               1.0|\n",
      "|  0.1337317123428807|               1.0|\n",
      "| 0.14362250154543582|               1.0|\n",
      "| 0.15351329074799094|               1.0|\n",
      "| 0.16340407995054607|               1.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.9998678921859857\n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "CPU times: user 127 ms, sys: 17.7 ms, total: 145 ms\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegressionSummary\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "\n",
    "trainingSummary = bestLogistic.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>LinearSVC</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8268174687231141, 0.8261320074771027, 0.8286958407057525, 0.82616277354784, 0.8235896624409202, 0.8260151277894385, 0.8297603759650024, 0.8304491657812564, 0.8248175814843852, 0.8293411329581271, 0.8270774989909728, 0.8248659809571827, 0.8278779451161176, 0.8283488329454913, 0.8242101079768207, 0.8268451585675043, 0.8260037834751355, 0.8282770782943996, 0.826462639315843, 0.8264841931022189, 0.8271715238527055, 0.826980489751999, 0.8276612721927648, 0.8274341102260567, 0.8243700402517584, 0.8267886340341721, 0.8263819259054923, 0.8259909458069702, 0.823533730807501, 0.824767651906768, 0.8291546755769761, 0.8277425460521606, 0.8267588653281482, 0.8240879304452569, 0.8270839730134444, 0.8258897348204209]\n",
      "CPU times: user 41.3 s, sys: 11.4 s, total: 52.6 s\n",
      "Wall time: 1h 48min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "estimator = LinearSVC()\n",
    "paramMaps = ParamGridBuilder()\\\n",
    "            .addGrid(LinearSVC.maxIter, [10, 50, 100])\\\n",
    "            .addGrid(LinearSVC.regParam, [0.01, 0.1, 1.0, 10])\\\n",
    "            .addGrid(LinearSVC.aggregationDepth, [10, 20, 30])\\\n",
    "            .build()\n",
    "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName = \"f1\")\n",
    "\n",
    "crossval = CrossValidator(estimator = estimator,estimatorParamMaps = paramMaps, evaluator = evaluator, numFolds = 5)\n",
    "cvModel = crossval.fit(train_balanced)\n",
    "print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectSubModels: Param for whether to collect a list of sub-models trained during tuning. If set to false, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. (default: False)\n",
      "estimator: estimator to be cross-validated (current: LinearSVC_ae3b83dcdd4f)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 10}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 20}, {Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='undefined', name='regParam', doc='regularization parameter (>= 0).'): 10.0, Param(parent='undefined', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 30}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_b889e110ccc5)\n",
      "numFolds: number of folds for cross validation (default: 3, current: 5)\n",
      "parallelism: the number of threads to use when running parallel algorithms (>= 1). (default: 1)\n",
      "seed: random seed. (default: 7809051150349531440)\n"
     ]
    }
   ],
   "source": [
    "print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989110505804938\n",
      "0.8100632628051736\n",
      "  \n",
      "9898\n",
      "9668\n",
      "230\n",
      "CPU times: user 162 ms, sys: 47.8 ms, total: 210 ms\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bestSVC = cvModel.bestModel\n",
    "train_pred = bestSVC.transform(train_balanced)\n",
    "train_auc = evaluator.evaluate(train_pred)\n",
    "print(train_auc)\n",
    "test_pred = bestSVC.transform(test)\n",
    "test_auc = evaluator.evaluate(test_pred)\n",
    "print(test_auc)\n",
    "print(\"  \")\n",
    "print(test_pred.count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestNaive.save('data/bestNaive')\n",
    "bestLogistic.save('data/bestLogistic')\n",
    "bestSVC.save('data/bestSVC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5.2 BAG OF WORDS  MACHINE LEARNING  (ensembles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>switch to a smaller training set as the system log report OOM </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165, 0.616136378762165]\n",
      "CPU times: user 25.7 s, sys: 5.07 s, total: 30.7 s\n",
      "Wall time: 56min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "paramMaps = ParamGridBuilder()\\\n",
    "            .addGrid(RandomForestClassifier.maxDepth, [5, 10, 20])\\\n",
    "            .addGrid(RandomForestClassifier.minInstancesPerNode, [1, 10, 50])\\\n",
    "            .addGrid(RandomForestClassifier.numTrees, [10, 20, 50])\\\n",
    "            .addGrid(RandomForestClassifier.subsamplingRate, [0.1, 0.5, 1.0])\\\n",
    "            .build()\n",
    "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName = \"f1\")\n",
    "\n",
    "crossval = CrossValidator(estimator = estimator,estimatorParamMaps = paramMaps, evaluator = evaluator, numFolds = 5)\n",
    "cvModel = crossval.fit(train_small)\n",
    "print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectSubModels: Param for whether to collect a list of sub-models trained during tuning. If set to false, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. (default: False)\n",
      "estimator: estimator to be cross-validated (current: RandomForestClassifier_05d9cd4cc04e)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 10, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 50, Param(parent='undefined', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_4474130a602f)\n",
      "numFolds: number of folds for cross validation (default: 3, current: 5)\n",
      "parallelism: the number of threads to use when running parallel algorithms (>= 1). (default: 1)\n",
      "seed: random seed. (default: 7809051150349531440)\n"
     ]
    }
   ],
   "source": [
    "print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316703792221229\n",
      "0.6259974405469813\n",
      "  \n",
      "9898\n",
      "9785\n",
      "113\n",
      "CPU times: user 117 ms, sys: 3.5 ms, total: 120 ms\n",
      "Wall time: 57.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bestRandomForest = cvModel.bestModel\n",
    "train_pred = bestRandomForest.transform(train_balanced)\n",
    "train_auc = evaluator.evaluate(train_pred)\n",
    "print(train_auc)\n",
    "test_pred = bestRandomForest.transform(test)\n",
    "test_auc = evaluator.evaluate(test_pred)\n",
    "print(test_auc)\n",
    "print(\"  \")\n",
    "print(test_pred.count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestRandomForest.save('data/bestRandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779, 0.6555980514942779]\n",
      "CPU times: user 46.6 s, sys: 11 s, total: 57.6 s\n",
      "Wall time: 7h 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "estimator = GBTClassifier()\n",
    "paramMaps = ParamGridBuilder()\\\n",
    "            .addGrid(GBTClassifier.maxDepth, [10, 20])\\\n",
    "            .addGrid(GBTClassifier.minInstancesPerNode, [5, 20])\\\n",
    "            .addGrid(GBTClassifier.maxIter, [20, 50])\\\n",
    "            .addGrid(GBTClassifier.stepSize, [0.1, 0.3])\\\n",
    "            .addGrid(GBTClassifier.subsamplingRate, [0.1, 0.5])\\\n",
    "            .build()\n",
    "            \n",
    "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName = \"f1\")\n",
    "\n",
    "crossval = CrossValidator(estimator = estimator,estimatorParamMaps = paramMaps, evaluator = evaluator, numFolds = 5)\n",
    "cvModel = crossval.fit(train_small)\n",
    "print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectSubModels: Param for whether to collect a list of sub-models trained during tuning. If set to false, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. (default: False)\n",
      "estimator: estimator to be cross-validated (current: GBTClassifier_656447602adb)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.1}, {Param(parent='undefined', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='undefined', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20, Param(parent='undefined', name='maxIter', doc='max number of iterations (>= 0).'): 50, Param(parent='undefined', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.3, Param(parent='undefined', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.5}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_e731ea0f1565)\n",
      "numFolds: number of folds for cross validation (default: 3, current: 5)\n",
      "parallelism: the number of threads to use when running parallel algorithms (>= 1). (default: 1)\n",
      "seed: random seed. (default: 7809051150349531440)\n"
     ]
    }
   ],
   "source": [
    "print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715786958978393\n",
      "0.6605093582827246\n",
      "  \n",
      "9898\n",
      "9393\n",
      "505\n",
      "CPU times: user 93.9 ms, sys: 6.01 ms, total: 99.9 ms\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bestGBT = cvModel.bestModel\n",
    "train_pred = bestGBT.transform(train_balanced)\n",
    "train_auc = evaluator.evaluate(train_pred)\n",
    "print(train_auc)\n",
    "test_pred = bestGBT.transform(test)\n",
    "test_auc = evaluator.evaluate(test_pred)\n",
    "print(test_auc)\n",
    "print(\"  \")\n",
    "print(test_pred.count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestGBT.save('data/bestGBT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6 SIMPLE NETWORK (Multilayer perceptron classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>not working for now,  will try this again on next unit</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# estimator = MultilayerPerceptronClassifier()\n",
    "# paramMaps = ParamGridBuilder()\\\n",
    "#             .addGrid(MultilayerPerceptronClassifier.maxIter, [100])\\\n",
    "#             .addGrid(MultilayerPerceptronClassifier.layers, [[65536, 65536,32768, 2],[65536, 16384,8192, 2],[65536, 4096, 2048, 2]])\\\n",
    "#             .addGrid(MultilayerPerceptronClassifier.blockSize, [128])\\\n",
    "#             .addGrid(MultilayerPerceptronClassifier.stepSize, [0.03])\\\n",
    "#             .build()\n",
    "\n",
    "# evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderROC\")\n",
    "\n",
    "# crossval = CrossValidator(estimator = estimator,estimatorParamMaps = paramMaps, evaluator = evaluator, numFolds = 5)\n",
    "# cvModel = crossval.fit(train_balanced)\n",
    "# print(cvModel.avgMetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(crossval.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# bestMPC = cvModel.bestModel\n",
    "# train_pred = bestMPC.transform(train_balanced)\n",
    "# train_auc = evaluator.evaluate(train_pred)\n",
    "# print(train_auc)\n",
    "# test_pred = bestMPC.transform(test)\n",
    "# test_auc = evaluator.evaluate(test_pred)\n",
    "# print(test_auc)\n",
    "# print(\"  \")\n",
    "# print(test_pred.count())\n",
    "# print(test_pred.filter(test_pred.label - test_pred.prediction == 0).count())\n",
    "# print(test_pred.filter(test_pred.label - test_pred.prediction != 0.0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestMPC.save('data/bestMPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<B>\n",
    "Load the best model from each algorithm and compare on the prediction using hold set. The auc score shows the LogisticRegression and LinearSVC has better result, As expected, the LogisticRegression is a stable algorithm which is good for buttom line modeling. The overall scores are similar to the result using sklearn  package. \n",
    "</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel, RandomForestClassificationModel, MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel, LinearSVCModel, NaiveBayesModel\n",
    "\n",
    "bestNaive = NaiveBayesModel.load('data/bestNaive')\n",
    "bestLogistic = LogisticRegressionModel.load('data/bestLogistic')\n",
    "bestSVC = LinearSVCModel.load('data/bestSVC')\n",
    "bestRandomForest = RandomForestClassificationModel.load('data/bestRandomForest')\n",
    "bestGBT = GBTClassificationModel.load('data/bestGBT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34822667859956374\n",
      "12358\n",
      "12237\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "hold_pred = bestNaive.transform(hold)\n",
    "hold_auc = evaluator.evaluate(hold_pred)\n",
    "print(hold_auc)\n",
    "\n",
    "print(hold_pred.count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction == 0).count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction != 0.0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8398202830668989\n",
      "12358\n",
      "11760\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "hold_pred = bestLogistic.transform(hold)\n",
    "hold_auc = evaluator.evaluate(hold_pred)\n",
    "print(hold_auc)\n",
    "\n",
    "print(hold_pred.count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction == 0).count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction != 0.0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627146313753249\n",
      "12358\n",
      "12061\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "hold_pred = bestSVC.transform(hold)\n",
    "hold_auc = evaluator.evaluate(hold_pred)\n",
    "print(hold_auc)\n",
    "\n",
    "print(hold_pred.count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction == 0).count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction != 0.0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6079497344573124\n",
      "12358\n",
      "12236\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "hold_pred = bestRandomForest.transform(hold)\n",
    "hold_auc = evaluator.evaluate(hold_pred)\n",
    "print(hold_auc)\n",
    "\n",
    "print(hold_pred.count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction == 0).count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction != 0.0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6546233500715438\n",
      "12358\n",
      "11736\n",
      "622\n"
     ]
    }
   ],
   "source": [
    "hold_pred = bestGBT.transform(hold)\n",
    "hold_auc = evaluator.evaluate(hold_pred)\n",
    "print(hold_auc)\n",
    "\n",
    "print(hold_pred.count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction == 0).count())\n",
    "print(hold_pred.filter(hold_pred.label - hold_pred.prediction != 0.0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Reference Imbalanced</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How pyspark handling unbalanced? basically under sample  \n",
    "[PySpark tutorial – a case study using Random Forest on unbalanced dataset](https://weiminwang.blog/2016/06/09/pyspark-tutorial-building-a-random-forest-binary-classifier-on-unbalanced-dataset/)\n",
    "\n",
    "[Class Imbalance in Credit Card Fraud Detection - Part 3 : Undersampling in Spark](http://blog.madhukaraphatak.com/class-imbalance-part-3/)\n",
    "\n",
    "[Healthcare Dataset with Spark](https://towardsdatascience.com/healthcare-dataset-with-spark-6bf48019892b)\n",
    "\n",
    "[Credit Card Fraud Detection Analysis on Imbalanced Data - Part 4](https://www.analyzeinsights.com/single-post/2017/10/23/Part-4-Credit-Card-Fraud-Detection-Analysis-on-Imbalanced-Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Reference Spark NLP</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Comprehensive Guide to Understand and Implement Text Classification in Python](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)  \n",
    "\n",
    "\n",
    "[Ultimate Guide to Understand and; Implement Natural Language Processing (with codes in Python)](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/) \n",
    "\n",
    "[An implementation guide to Word2Vec using NumPy and Google Sheets](https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281) \n",
    "\n",
    "[Approaching (Almost) Any NLP Problem on Kaggle](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below articles using RDD to apply NLTK, this is just for reference\n",
    "\n",
    "[Natural language processing in Apache Spark using NLTK  part 1](https://towardsdatascience.com/natural-language-processing-in-apache-spark-using-nltk-part-1-2-58c68824f660)\n",
    "\n",
    "[Natural language processing in Apache Spark using NLTK  part 2](https://towardsdatascience.com/natural-language-processing-in-apache-spark-using-nltk-part-2-2-5550b85f3340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
